Train MNIST using numpy with manual backprop (more accurate than pytorch )

# pytorch loss.backward() : 0.964 
# backprop by hand : 0.977 

![image](https://github.com/utkarshgill/mnist_from_scratch/assets/46515280/a056ba8b-85b7-4fe8-a826-0c36ca030d84)
